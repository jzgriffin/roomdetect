\documentclass{article}

\usepackage{etoolbox}
\usepackage{float}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{pgf}
\usepackage{tikz}

\newtoggle{TASKSPECONLY}

\geometry{margin=1in}

\graphicspath{ {figures/}{photos/} }

\usetikzlibrary{arrows}
\usetikzlibrary{automata}
\usetikzlibrary{fit}
\usetikzlibrary{positioning}
\tikzset{initial text={}}

\title{Report: Room Detector}
\author{Jeremiah Griffin}
\date{Spring 2017}

\begin{document}

\pagenumbering{gobble}
\maketitle
\newpage

\pagenumbering{roman}
\tableofcontents
\newpage

\pagenumbering{arabic}

\section{Introduction}

The room detector uses inputs from several sensors to determine what
room or environment the device is currently in.  It uses a statistical
model to associate ambient factors with a user-defined room number.  The
network must be trained by the user before it may be used.  This is done
online by placing the device in each room to be detected, entering
training mode, associating either a new or existing room number with the
training data, and then moving the device through the room.  The longer
the device is trained, the more accurate its classifications become.
Once training is complete, the device may enter detection mode and be
moved between any of the trained rooms.  If brought to an untrained
room, it will make its best guess at classifying the room as one that
was trained.

\begin{figure}[h]
  \centering
  \noindent\includegraphics[width = \textwidth]{overview}
  \caption{Overview photo of project hardware}
  \label{photo:1}
\end{figure}

\section{Hardware}

\subsection{Parts}

The hardware components that were used in this project are listed below.
The equipment that was not taught as part of the course material is
listed in bold.

\begin{table}[h!]
  \centering
  \begin{tabular}{llr}
    Part Number & Component & Quantity \\
    \hline
    ATmega1284p             & Microcontroller                  & 2 \\
                            & SPDT toggle switch               & 1 \\
                            & SPST push-down button            & 3 \\
                            & 10K\Omega\ trimmer potentiometer & 1 \\
                            & 330\Omega\ 10\% resistor         & 4 \\
                            & CdS photoresistor                & 1 \\
    LCM-S01602DTR/M         & Liquid crystal display           & 1 \\
    \textbf{TMP36}          & Temperature sensor               & 1 \\
    \textbf{CMA-4544PF-W}   & Electret microphone              & 1 \\
    \textbf{MAX9814}        & Microphone amplifier             & 1
  \end{tabular}
  \caption{Listing of parts used in design}
  \label{table:1}
\end{table}

\subsection{Pinout}

\begin{figure}[H]
  \centering
  \noindent\includegraphics[scale=1.10]{pinout}
  \caption{Pinout and schematic for project}
  \label{schematic:1}
\end{figure}

\section{Software}

The software designed for this project was implemented using the PES
standard.  The overall design as a task diagram is included below.

\begin{figure}[H]
  \centering
  \noindent\includegraphics[width = \textwidth]{task_diagram}
  \caption{Task diagram for project}
  \label{task:1}
\end{figure}

The master and compute tasks run on their respective microcontrollers.
The common tasks run independently on both microcontrollers, being part
of a static library linked to by both microcontroller applications and
instantiated in their task schedulers.  The inputs and outputs for the
common LCD, USART TX, USART RX, and packet RX tasks were excluded from
this diagram for brevity but are documented in their task descriptions.

In the following sections, the individual tasks from the above diagram
are briefly described in addition to their inputs and outputs.  The
state machines for these tasks are presented in appendix \ref{app.sm}.

\subsection{Tasks}

\toggletrue{TASKSPECONLY}

\subsubsection{Master Mode Task}
\input{figures/master_mode_task.tex}

Sets \verb#device_mode# to \verb#DETECTION# if \verb#PA0# is low and to
\verb#TRAINING# if it's high.  This controls which of the detection and
training tasks is enabled.

\subsubsection{Master Detection Task}
\input{figures/master_detection_task.tex}

Operates when \verb#device_mode# is \verb#DETECTION#.  Receives
detection packets from the compute microcontroller.  Responds to the
save, reset, and erase buttons by sending the appropriate packets to the
compute microcontroller to adjust the model.

\subsubsection{Master Training Task}
\input{figures/master_training_task.tex}

Operates when \verb#device_mode# is \verb#TRAINING#.  Responds to the
increment, decrement, and confirm buttons by adjusting the training room
and sending the appropriate packets to the compute microcontroller to
begin and end training.  Sets \verb#is_training# to true when training.

\subsubsection{Master Display Task}
\input{figures/master_display_task.tex}

Outputs messages to the LCD according to the current state and detected
or training room.  Controlled by the detection and training tasks.

\subsubsection{Compute Mode Task}
\input{figures/compute_mode_task.tex}

Sets \verb#device_mode# to \verb#DETECTION# when a stop-training packet
is received and to \verb#TRAINING# when a start-training packet is
received.  Sets \verb#training_room# to the room indicated in the
start-training packet.

\subsubsection{Compute Reading Task}
\input{figures/compute_reading_task.tex}

Samples from the analog inputs in sequence when
\verb#should_poll_readings# is true to create the \verb#reading_vector#.
Calculates the mean of 16 samples through time to smooth noise.
Indicates when the reading vector is populated by setting
\verb#are_readings_ready# to true.

\subsubsection{Compute Detection Task}
\input{figures/compute_detection_task.tex}

Classifies the current reading vector using the classification model
when \verb#are_readings_ready# is high and \verb#device_mode# is
\verb#DETECTION#.  Outputs the classification result to
\verb#detected_room#.

\subsubsection{Compute Training Task}
\input{figures/compute_training_task.tex}

Integrates the current reading vector into the classification model when
\verb#are_readings_ready# is high and \verb#device_mode# is
\verb#TRAINING#.

\subsubsection{Common LCD Task}
\input{figures/common_lcd_task.tex}

Clears the LCD when \verb#should_lcd_clear# is true.  Writes the
contents of \verb#lcd_buffer# to the LCD at \verb#lcd_position# when
\verb#should_lcd_write# is true.  Sets \verb#is_lcd_ready# to true when
the current operation is complete.

\subsubsection{Common USART TX Task}
\input{figures/common_usart_tx_task.tex}

Transmits bytes over USART from the TX queue.

\subsubsection{Common USART RX Task}
\input{figures/common_usart_rx_task.tex}

Receives bytes from USART into the RX queue.

\subsubsection{Common Packet RX Task}
\input{figures/common_usart_packet_rx_task.tex}

Identifies and receives packets from the USART RX queue into the packet
RX queue.  When active, non-packet bytes are discarded from the
queue--thus only packet communication is possible when scheduled.

\section{Complexities}

\subsection{Complete}

\begin{itemize}

  \item Using EEPROM to persist the classification model state

  \item Using USART to offload computation to a dedicated
    microcontroller

  \item Using ADC multiplexing to collect analog readings from multiple
    sensors

  \item Using a temperature sensor and microphone obtained outside of
    the lab kit

  \item Using a statistical model to perform input classification using
    fixed-point arithmetic

\end{itemize}

\subsection{Incomplete}

\begin{itemize}

  \item Using a neural network to perform input classification using
    fixed-point arithmetic \\
    This complexity could not be completed due to hardware limitations.
    Its role in the project was instead filled by the statistical model
    listed above.  The intended design for the neural network was a
    multi-layer feed-forward network, with one input layer of size 4,
    one hidden layer of size 10 with a linear activation function, one
    hidden layer of size 10 with a hyperbolic tangent activation
    function, one hidden layer of size 16 with a linear activation
    function, and one output layer of size 16 with a softmax activation
    function.  This topology was chosen as the best for fulfilling the
    goal of classifying three inputs, with one bias input, into one of
    16 outputs.  However, this network proved too large for the ATmega
    to process.  When including the amount of memory necessary for
    storing training state, the network became too large for storage in
    the ATmega's 16 kilobyte SRAM.  Additionally, even using fixed-point
    arithmetic in place of traditional floating point, the times for
    classification became slower than was considered acceptable and the
    times for training made it obvious that training would only be
    possible offline using a faster device, which was deemed to be
    beyond the scope of this project.  As a result of these limitations,
    the neural network was replaced with a simpler statistical model at
    the cost of accuracy and robustness when faced with input noise.

\end{itemize}

\section{Links}

\begin{description}

  \item [Demonstration Video] https://youtu.be/Kw6NZRzlpkQ

  \item [GitHub Repository] https://github.com/nokurn/roomdetect

\end{description}

\section{Known Issues}

\begin{itemize}

  \item The classification algorithm does not cope well with noise and
    may confuse environments with a large degree of noise as being
    equivalent regardless of the specifics of that noise.

  \item The temperature sensor is not measured with sufficient precision
    for its readings to adequately influence the results of the
    classification.

  \item The microphone primarily distinguishes between noisy and quiet
    environments with no consideration of the qualities of the sound
    such as timbre and pitch.

  \item The classifier most heavily relies on the measurements from the
    photo-resistor, despite unbiased treatment of all readings in the
    input vector.  This is likely due to the aforementioned reasons:
    low analog precision and the need for pre-processing of some
    readings.

\end{itemize}

\section{Future Work}

\begin{itemize}

  \item The largest improvement might come from replacing the compute
    microcontroller with a higher-power compute unit, possibly
    integrating floating-point arithmetic, and using a more robust
    classification model such as a neural network.

  \item By using an external analog-digital converter with higher
    precision, or simply replacing the ATmega with a microcontroller
    with a higher-precision integrated ADC, sensors with small output
    ranges would contribute more to the accuracy and confidence of the
    device's classifications.  This would reflect immediately in the
    ability of the device to distinguish between environments with
    slightly different temperatures.

  \item Applying a Fourier transform to the microphone signal and using
    the individual components as input to the classifier would improve
    the quality of classifications with regard to environmental sounds.
    For example, if one room contains several computers with spinning
    fans and another room has a single ceiling fan, yet the volume level
    in both rooms is similar, a Fourier analysis of the sound waves
    would enable the classifier to distinguish between the two by the
    timbre and pitch of the sound in addition to its loudness.

  \item Adding additional sensors would increase the size of the
    classifier's feature vector and its accuracy.  Barometric pressure,
    humidity, altitude, or even GPS would be likely candidates for
    inclusion in the system.

\end{itemize}

\appendix

\section{Appendix: State Machines}
\label{app.sm}

\togglefalse{TASKSPECONLY}

\subsection{Master Microcontroller}
\label{app.sm.master}

\begin{figure}[H]
  \centering
  \caption{State machine for master mode task}
  \input{figures/master_mode_task.tex}
  \label{sm:1}
\end{figure}

\begin{figure}[H]
  \centering
  \caption{State machine for master detection task}
  \input{figures/master_detection_task.tex}
  \label{sm:2}
\end{figure}

\begin{figure}[H]
  \centering
  \caption{State machine for master training task}
  \input{figures/master_training_task.tex}
  \label{sm:3}
\end{figure}

\begin{figure}[H]
  \centering
  \caption{State machine for master display task}
  \input{figures/master_display_task.tex}
  \label{sm:4}
\end{figure}

\subsection{Compute Microcontroller}
\label{app.sm.compute}

\begin{figure}[H]
  \centering
  \caption{State machine for compute mode task}
  \input{figures/compute_mode_task.tex}
  \label{sm:5}
\end{figure}

\begin{figure}[H]
  \centering
  \caption{State machine for compute reading task}
  \input{figures/compute_reading_task.tex}
  \label{sm:6}
\end{figure}

\begin{figure}[H]
  \centering
  \caption{State machine for compute detection task}
  \input{figures/compute_detection_task.tex}
  \label{sm:7}
\end{figure}

\begin{figure}[H]
  \centering
  \caption{State machine for compute training task}
  \input{figures/compute_training_task.tex}
  \label{sm:8}
\end{figure}

\subsection{Common Infrastructure}
\label{app.sm.common}

\begin{figure}[H]
  \centering
  \caption{State machine for common LCD task}
  \input{figures/common_lcd_task.tex}
  \label{sm:9}
\end{figure}

\begin{figure}[H]
  \centering
  \caption{State machine for common USART TX task}
  \input{figures/common_usart_tx_task.tex}
  \label{sm:10}
\end{figure}

\begin{figure}[H]
  \centering
  \caption{State machine for common USART RX task}
  \input{figures/common_usart_rx_task.tex}
  \label{sm:11}
\end{figure}

\begin{figure}[H]
  \centering
  \caption{State machine for common USART packet RX task}
  \input{figures/common_usart_packet_rx_task.tex}
  \label{sm:12}
\end{figure}

\end{document}
